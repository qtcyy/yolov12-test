#!/usr/bin/env python3
"""
éªŒè¯é›†æ ‡æ³¨å¯è§†åŒ–è„šæœ¬
å°†éªŒè¯é›†ä¸­çš„æ ‡å‡†æ ‡æ³¨æ•°æ®åœ¨å›¾åƒä¸­æ¡†å‡ºï¼Œä¿å­˜åˆ°æŒ‡å®šæ–‡ä»¶å¤¹

ä½¿ç”¨æ–¹æ³•:
    python src/visualize_val_annotations.py [--max_images 100] [--show_stats]
"""

import argparse
import json
import time
from pathlib import Path
from collections import defaultdict

import cv2
from tqdm import tqdm


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="éªŒè¯é›†æ ‡æ³¨å¯è§†åŒ–")

    # è¾“å…¥è¾“å‡ºå‚æ•°
    parser.add_argument(
        "--images_dir",
        type=str,
        default="../dataset_yolo/images/val",
        help="éªŒè¯é›†å›¾åƒç›®å½•"
    )
    parser.add_argument(
        "--labels_dir",
        type=str,
        default="../dataset_yolo/labels/val",
        help="éªŒè¯é›†æ ‡æ³¨ç›®å½•"
    )
    parser.add_argument(
        "--output_dir",
        type=str,
        default="../dataset_yolo/val_standard",
        help="å¯è§†åŒ–è¾“å‡ºç›®å½•"
    )

    # å¤„ç†é€‰é¡¹
    parser.add_argument(
        "--max_images",
        type=int,
        default=None,
        help="æœ€å¤§å¤„ç†å›¾åƒæ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰"
    )
    parser.add_argument(
        "--show_stats",
        action="store_true",
        help="æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"
    )
    parser.add_argument(
        "--box_thickness",
        type=int,
        default=2,
        help="è¾¹ç•Œæ¡†çº¿æ¡ç²—ç»†"
    )
    parser.add_argument(
        "--font_scale",
        type=float,
        default=0.6,
        help="æ ‡ç­¾å­—ä½“å¤§å°"
    )

    return parser.parse_args()


def load_class_names():
    """åŠ è½½ç±»åˆ«åç§°ï¼ˆä¸coco_dataset.yamlä¸€è‡´ï¼‰"""
    return {
        0: "ship",
        1: "people",
        2: "car",
        3: "motor"
    }


def get_class_colors():
    """è·å–å„ç±»åˆ«çš„é¢œè‰²ï¼ˆBGRæ ¼å¼ï¼‰"""
    return {
        0: (255, 255, 0),  # ship - é’è‰²
        1: (255, 0, 255),  # people - ç´«è‰²
        2: (0, 255, 255),  # car - é»„è‰²
        3: (0, 255, 0)  # motor - ç»¿è‰²
    }


def read_yolo_annotation(label_path, img_width, img_height):
    """
    è¯»å–YOLOæ ¼å¼çš„æ ‡æ³¨æ–‡ä»¶

    Args:
        label_path: æ ‡æ³¨æ–‡ä»¶è·¯å¾„
        img_width: å›¾åƒå®½åº¦
        img_height: å›¾åƒé«˜åº¦

    Returns:
        List[dict]: è¾¹ç•Œæ¡†ä¿¡æ¯åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«class_id, x1, y1, x2, y2
    """
    annotations = []

    if not label_path.exists():
        return annotations

    with open(label_path, 'r') as f:
        for line in f:
            line = line.strip()
            if not line:
                continue

            parts = line.split()
            if len(parts) < 5:
                continue

            class_id = int(parts[0])
            x_center = float(parts[1])
            y_center = float(parts[2])
            width = float(parts[3])
            height = float(parts[4])

            # è½¬æ¢ä¸ºåƒç´ åæ ‡
            x_center_px = x_center * img_width
            y_center_px = y_center * img_height
            width_px = width * img_width
            height_px = height * img_height

            # è®¡ç®—è¾¹ç•Œæ¡†åæ ‡
            x1 = int(x_center_px - width_px / 2)
            y1 = int(y_center_px - height_px / 2)
            x2 = int(x_center_px + width_px / 2)
            y2 = int(y_center_px + height_px / 2)

            # ç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…
            x1 = max(0, min(x1, img_width - 1))
            y1 = max(0, min(y1, img_height - 1))
            x2 = max(0, min(x2, img_width - 1))
            y2 = max(0, min(y2, img_height - 1))

            annotations.append({
                'class_id': class_id,
                'x1': x1,
                'y1': y1,
                'x2': x2,
                'y2': y2
            })

    return annotations


def draw_annotations(image, annotations, class_names, class_colors, box_thickness=2, font_scale=0.6):
    """
    åœ¨å›¾åƒä¸Šç»˜åˆ¶æ ‡æ³¨

    Args:
        image: è¾“å…¥å›¾åƒ
        annotations: æ ‡æ³¨åˆ—è¡¨
        class_names: ç±»åˆ«åç§°å­—å…¸
        class_colors: ç±»åˆ«é¢œè‰²å­—å…¸
        box_thickness: è¾¹ç•Œæ¡†çº¿æ¡ç²—ç»†
        font_scale: å­—ä½“å¤§å°

    Returns:
        ç»˜åˆ¶åçš„å›¾åƒ
    """
    img_draw = image.copy()

    for ann in annotations:
        class_id = ann['class_id']
        x1, y1, x2, y2 = ann['x1'], ann['y1'], ann['x2'], ann['y2']

        # è·å–ç±»åˆ«ä¿¡æ¯
        class_name = class_names.get(class_id, f"unknown_{class_id}")
        color = class_colors.get(class_id, (128, 128, 128))  # é»˜è®¤ç°è‰²

        # ç»˜åˆ¶è¾¹ç•Œæ¡†
        cv2.rectangle(img_draw, (x1, y1), (x2, y2), color, box_thickness)

        # å‡†å¤‡æ ‡ç­¾æ–‡æœ¬
        label = f"{class_name}"

        # è®¡ç®—æ–‡æœ¬å¤§å°
        font = cv2.FONT_HERSHEY_SIMPLEX
        (text_width, text_height), baseline = cv2.getTextSize(
            label, font, font_scale, 2
        )

        # ç»˜åˆ¶æ–‡æœ¬èƒŒæ™¯
        label_x1 = x1
        label_y1 = y1 - text_height - 10
        label_x2 = x1 + text_width + 8
        label_y2 = y1

        # ç¡®ä¿æ ‡ç­¾åœ¨å›¾åƒå†…
        if label_y1 < 0:
            label_y1 = y2
            label_y2 = y2 + text_height + 10

        cv2.rectangle(img_draw, (label_x1, label_y1), (label_x2, label_y2), color, -1)

        # ç»˜åˆ¶æ–‡æœ¬
        text_x = label_x1 + 4
        text_y = label_y2 - 5
        cv2.putText(
            img_draw, label, (text_x, text_y), font, font_scale, (255, 255, 255), 2
        )

    return img_draw


def process_single_image(image_path, label_path, output_path, class_names, class_colors, args):
    """
    å¤„ç†å•å¼ å›¾åƒ

    Args:
        image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
        label_path: æ ‡æ³¨æ–‡ä»¶è·¯å¾„
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        class_names: ç±»åˆ«åç§°å­—å…¸
        class_colors: ç±»åˆ«é¢œè‰²å­—å…¸
        args: å‘½ä»¤è¡Œå‚æ•°

    Returns:
        dict: å¤„ç†ç»“æœç»Ÿè®¡
    """
    try:
        # è¯»å–å›¾åƒ
        image = cv2.imread(str(image_path))
        if image is None:
            return {'success': False, 'error': 'Cannot read image', 'annotations': 0}

        img_height, img_width = image.shape[:2]

        # è¯»å–æ ‡æ³¨
        annotations = read_yolo_annotation(label_path, img_width, img_height)

        # ç»˜åˆ¶æ ‡æ³¨
        if annotations:
            image_with_annotations = draw_annotations(
                image, annotations, class_names, class_colors,
                args.box_thickness, args.font_scale
            )
        else:
            # å¦‚æœæ²¡æœ‰æ ‡æ³¨ï¼Œç›´æ¥å¤åˆ¶åŸå›¾
            image_with_annotations = image.copy()

        # ä¿å­˜ç»“æœ
        cv2.imwrite(str(output_path), image_with_annotations)

        return {
            'success': True,
            'annotations': len(annotations),
            'classes': [ann['class_id'] for ann in annotations]
        }

    except Exception as e:
        return {'success': False, 'error': str(e), 'annotations': 0}


def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()

    print("=" * 60)
    print("éªŒè¯é›†æ ‡æ³¨å¯è§†åŒ–")
    print("=" * 60)

    # æ£€æŸ¥è¾“å…¥ç›®å½•
    images_dir = Path(args.images_dir)
    labels_dir = Path(args.labels_dir)

    if not images_dir.exists():
        print(f"âŒ é”™è¯¯: å›¾åƒç›®å½•ä¸å­˜åœ¨ {images_dir}")
        return

    if not labels_dir.exists():
        print(f"âŒ é”™è¯¯: æ ‡æ³¨ç›®å½•ä¸å­˜åœ¨ {labels_dir}")
        return

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # åŠ è½½ç±»åˆ«ä¿¡æ¯
    class_names = load_class_names()
    class_colors = get_class_colors()

    # è·å–å›¾åƒæ–‡ä»¶
    image_extensions = [".jpg", ".jpeg", ".png", ".bmp"]
    image_files = []
    for ext in image_extensions:
        image_files.extend(list(images_dir.glob(f"*{ext}")))
        image_files.extend(list(images_dir.glob(f"*{ext.upper()}")))

    image_files = sorted(image_files)

    if args.max_images:
        image_files = image_files[:args.max_images]

    print(f"\næ‰¾åˆ° {len(image_files)} å¼ å›¾åƒ")

    if len(image_files) == 0:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•å›¾åƒæ–‡ä»¶")
        return

    # æ˜¾ç¤ºå¤„ç†é…ç½®
    print(f"\nå¤„ç†é…ç½®:")
    print(f"  å›¾åƒç›®å½•: {images_dir}")
    print(f"  æ ‡æ³¨ç›®å½•: {labels_dir}")
    print(f"  è¾“å‡ºç›®å½•: {output_dir}")
    print(f"  è¾¹ç•Œæ¡†ç²—ç»†: {args.box_thickness}")
    print(f"  å­—ä½“å¤§å°: {args.font_scale}")
    print(f"  æ˜¾ç¤ºç»Ÿè®¡: {args.show_stats}")

    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'total_images': len(image_files),
        'processed_images': 0,
        'failed_images': 0,
        'total_annotations': 0,
        'class_counts': defaultdict(int),
        'processing_times': [],
        'start_time': time.time()
    }

    # å¼€å§‹å¤„ç†
    print(f"\nå¼€å§‹å¤„ç†...")
    print("-" * 60)

    # å¤„ç†æ¯å¼ å›¾åƒ
    for image_path in tqdm(image_files, desc="å¤„ç†è¿›åº¦"):
        start_time = time.time()

        # æ„å»ºè·¯å¾„
        image_name = image_path.stem
        label_path = labels_dir / f"{image_name}.txt"
        output_path = output_dir / f"{image_name}.jpg"

        # å¤„ç†å›¾åƒ
        result = process_single_image(
            image_path, label_path, output_path,
            class_names, class_colors, args
        )

        # æ›´æ–°ç»Ÿè®¡
        if result['success']:
            stats['processed_images'] += 1
            stats['total_annotations'] += result['annotations']

            # ç»Ÿè®¡å„ç±»åˆ«æ•°é‡
            for class_id in result.get('classes', []):
                class_name = class_names.get(class_id, f"unknown_{class_id}")
                stats['class_counts'][class_name] += 1
        else:
            stats['failed_images'] += 1
            if args.show_stats:
                print(f"\nâš ï¸ å¤„ç†å¤±è´¥ {image_path.name}: {result.get('error', 'Unknown error')}")

        # è®°å½•å¤„ç†æ—¶é—´
        processing_time = time.time() - start_time
        stats['processing_times'].append(processing_time)

    # è®¡ç®—æ€»ä½“ç»Ÿè®¡
    total_time = time.time() - stats['start_time']
    avg_time = sum(stats['processing_times']) / len(stats['processing_times']) if stats['processing_times'] else 0
    fps = 1 / avg_time if avg_time > 0 else 0

    # æ˜¾ç¤ºç»“æœ
    print("\n" + "=" * 60)
    print("âœ… å¤„ç†å®Œæˆï¼")
    print("=" * 60)

    print(f"\nğŸ“Š å¤„ç†ç»Ÿè®¡:")
    print(f"  æ€»å›¾åƒæ•°é‡: {stats['total_images']}")
    print(f"  æˆåŠŸå¤„ç†: {stats['processed_images']}")
    print(f"  å¤„ç†å¤±è´¥: {stats['failed_images']}")
    print(f"  æ€»æ ‡æ³¨æ•°é‡: {stats['total_annotations']}")
    print(f"  å¹³å‡æ¯å¼ å›¾åƒ: {stats['total_annotations'] / stats['processed_images']:.2f} ä¸ªæ ‡æ³¨" if stats[
                                                                                                        'processed_images'] > 0 else "  å¹³å‡æ¯å¼ å›¾åƒ: 0 ä¸ªæ ‡æ³¨")

    print(f"\nâ±ï¸ å¤„ç†æ—¶é—´:")
    print(f"  æ€»å¤„ç†æ—¶é—´: {total_time:.2f} ç§’")
    print(f"  å¹³å‡å¤„ç†æ—¶é—´: {avg_time:.3f} ç§’/å¼ ")
    print(f"  å¤„ç†é€Ÿåº¦: {fps:.2f} FPS")

    print(f"\nğŸ“‹ å„ç±»åˆ«ç»Ÿè®¡:")
    for class_name, count in sorted(stats['class_counts'].items()):
        percentage = (count / stats['total_annotations']) * 100 if stats['total_annotations'] > 0 else 0
        color_info = ""
        for class_id, name in class_names.items():
            if name == class_name:
                color = class_colors.get(class_id, (128, 128, 128))
                color_info = f" (BGR: {color})"
                break
        print(f"  {class_name}: {count} ({percentage:.1f}%){color_info}")

    print(f"\nğŸ“ è¾“å‡ºä¿¡æ¯:")
    print(f"  è¾“å‡ºç›®å½•: {output_dir}")
    print(f"  è¾“å‡ºå›¾åƒ: {stats['processed_images']} å¼ ")

    if args.show_stats:
        print(f"\nğŸ’¡ ä½¿ç”¨è¯´æ˜:")
        print(f"  - é’è‰²è¾¹ç•Œæ¡†: ship (èˆ¹èˆ¶)")
        print(f"  - ç´«è‰²è¾¹ç•Œæ¡†: people (äºº)")
        print(f"  - é»„è‰²è¾¹ç•Œæ¡†: car (æ±½è½¦)")
        print(f"  - ç»¿è‰²è¾¹ç•Œæ¡†: motor (æ‘©æ‰˜è½¦)")


if __name__ == "__main__":
    main()
